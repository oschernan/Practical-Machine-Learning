{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Neural Networks - Oscar Hernandez "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this report will be to build several neural networks utilizing the MNIST dataset (images of digits 0-9). This is all part of the exploratory work being completed to evaluate machine learning technologies as it pertains to optical character recognition. Neural networks can be used for a variety of reasons but in this case it will be for classification purposes. Furthermore, this report will compare each of the neural networks using a benchmark experiment that uses a 2x2 factorial design. The factors that will be used are number of layers and nodes per layer. Various hyperparameter settings will be used. We will output the results of the benchmark experiment, draw conclusions from these results and make a recommendation on which neural network we believe is most trusthworthy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This report will be broken up into Sections that cover the specific methodology that went into arriving at the final recommendation. The report will include and/or cover, at minimum, the following specific items and/or tasks:\n",
    "* Explore the MNIST data set to get a quick understanding of its structure and standardize the entire data set  \n",
    "* Train 4 neural networks using the MNIST data set using different hyperparameter settings and factors\n",
    "* Record the time it took to train each neural network and the accuracy on the training data set\n",
    "* Test each neural network on a test set and record its accuracy \n",
    "* Provide final management recommendation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 - Exploratory Data Analysis & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first step in building a machine learning model is to gain a firm understanding of the data that will be used to train the model. Section 1 covers all the work that was completed as part of the Exploratory Data Analysis (EDA) process along with comments explaining code and output wherever necessary. Section 1 also covers any data preparation steps that were taken prior to building out the neural networks.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load all the necessary packages we need to complete the exercise\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import nbconvert\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the MNIST train data set which is 60,000 instances\n",
    "#Display the shape of the newly created object\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x15</th>\n",
       "      <th>1x16</th>\n",
       "      <th>1x17</th>\n",
       "      <th>1x18</th>\n",
       "      <th>1x19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.881816</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>216.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1x15          1x16     1x17     1x18     1x19\n",
       "count  60000.000000  60000.000000  60000.0  60000.0  60000.0\n",
       "mean       0.003600      0.000150      0.0      0.0      0.0\n",
       "std        0.881816      0.036742      0.0      0.0      0.0\n",
       "min        0.000000      0.000000      0.0      0.0      0.0\n",
       "25%        0.000000      0.000000      0.0      0.0      0.0\n",
       "50%        0.000000      0.000000      0.0      0.0      0.0\n",
       "75%        0.000000      0.000000      0.0      0.0      0.0\n",
       "max      216.000000      9.000000      0.0      0.0      0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outputs a statistical description of the training data set\n",
    "#We made a generic subset for formatting purposes \n",
    "#The key item to note is that we will need to scale it \n",
    "#based on the values that we see from the output\n",
    "quick_subset = train.iloc[:, 15:20]\n",
    "quick_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the MNIST test data set which is 10,000 instances\n",
    "#Display the shape of the newly created object\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, split the labels from train and test data set\n",
    "X_train = train.drop(\"label\", axis =1)\n",
    "y_train = train[\"label\"].copy()\n",
    "X_test = test.drop(\"label\", axis =1)\n",
    "y_test = test[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFBxJREFUeJzt3X+s3fV93/HnCzukIcmCKQYRm8Z0cZMQqRB6BaxsURo6Y8gasylI0KpYyJsnjfzaJi2k+wMNSkWkaTSR1khWcGaqNJTQRtAOhXgQOmUT4MuP8MtQO4Ri1wRuZ0PasiaDvPfH+bgcw72+5+J7z73weT6ko/P9vr+f7/m+v/je+zrfH+eQqkKS1J+jFrsBSdLiMAAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUrAGQ5H1JHhx6/CjJZ5Mcl2R7kl3teUUbnyRfSrI7yUNJzhh6rY1t/K4kGxdyxyRJh5e5fBI4yTLgL4GzgMuB/VV1bZIrgBVV9bkkFwCfAi5o475YVWclOQ6YBCaAAu4DfqmqDsy0veOPP77WrFnz+vZMkjp13333/VVVrZxt3PI5vu65wPer6i+SbAA+0urbgLuAzwEbgBtqkCx3Jzk2yUlt7Paq2g+QZDuwHvj6TBtbs2YNk5OTc2xRkvqW5C9GGTfXawAX88of7BOr6hmA9nxCq68C9gyts7fVZqofIsnmJJNJJqempubYniRpVCMHQJKjgY8D35ht6DS1Okz90ELVlqqaqKqJlStnPYKRJL1OczkCOB+4v6qebfPPtlM7tOfnWn0vcPLQequBfYepS5IWwVwC4BIOPV9/K3DwTp6NwC1D9Uvb3UBnAy+0U0S3A+uSrGh3DK1rNUnSIhjpInCSY4B/CvzrofK1wE1JNgFPAxe1+m0M7gDaDbwIXAZQVfuTXA3saOOuOnhBWJI0fnO6DXTcJiYmyruAJGluktxXVROzjfOTwJLUKQNAkjo11w+CLTlrrvjvR7T+U9d+bJ46kaQ3Fo8AJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn3vBfB70UHOlXUoNfSy1p/DwCkKROGQCS1CkDQJI65TWANxH/95iS5mKkI4Akxya5OcnjSXYm+UdJjkuyPcmu9ryijU2SLyXZneShJGcMvc7GNn5Xko0LtVOSpNmNegroi8C3qur9wGnATuAK4I6qWgvc0eYBzgfWtsdm4MsASY4DrgTOAs4ErjwYGpKk8Zs1AJL8A+DDwPUAVfWTqnoe2ABsa8O2ARe26Q3ADTVwN3BskpOA84DtVbW/qg4A24H187o3kqSRjXIE8PPAFPDVJA8k+UqStwMnVtUzAO35hDZ+FbBnaP29rTZT/RBJNieZTDI5NTU15x2SJI1mlIvAy4EzgE9V1T1Jvsgrp3umk2lqdZj6oYWqLcAWgImJidcs19Lmh+KkN45RAmAvsLeq7mnzNzMIgGeTnFRVz7RTPM8NjT95aP3VwL5W/8ir6ne9/talmS2FO6IMQy11swZAVf0wyZ4k76uqJ4BzgcfaYyNwbXu+pa1yK/DJJDcyuOD7QguJ24HfGbrwuw74/PzujqRXWwphqKVp1M8BfAr4WpKjgSeByxhcP7gpySbgaeCiNvY24AJgN/BiG0tV7U9yNbCjjbuqqvbPy15IkuZspACoqgeBiWkWnTvN2AIun+F1tgJb59KgpDe+pXI6zKOhQ/lVEJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnq1KjfBipJmgdL5YvxwCMASeqWASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnq1EgBkOSpJA8neTDJZKsdl2R7kl3teUWrJ8mXkuxO8lCSM4ZeZ2MbvyvJxoXZJUnSKOZyBPArVXV6VU20+SuAO6pqLXBHmwc4H1jbHpuBL8MgMIArgbOAM4ErD4aGJGn8juQU0AZgW5veBlw4VL+hBu4Gjk1yEnAesL2q9lfVAWA7sP4Iti9JOgKjBkAB305yX5LNrXZiVT0D0J5PaPVVwJ6hdfe22kz1QyTZnGQyyeTU1NToeyJJmpNRvw30nKral+QEYHuSxw8zNtPU6jD1QwtVW4AtABMTE69ZLkmaHyMdAVTVvvb8HPBNBufwn22ndmjPz7Xhe4GTh1ZfDew7TF2StAhmDYAkb0/yzoPTwDrgEeBW4OCdPBuBW9r0rcCl7W6gs4EX2imi24F1SVa0i7/rWk2StAhGOQV0IvDNJAfH/0FVfSvJDuCmJJuAp4GL2vjbgAuA3cCLwGUAVbU/ydXAjjbuqqraP297Ikmak1kDoKqeBE6bpv5/gHOnqRdw+QyvtRXYOvc2JUnzzU8CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVq5ABIsizJA0n+tM2fkuSeJLuS/GGSo1v9rW1+d1u+Zug1Pt/qTyQ5b753RpI0urkcAXwG2Dk0/wXguqpaCxwANrX6JuBAVb0XuK6NI8mpwMXAB4H1wO8lWXZk7UuSXq+RAiDJauBjwFfafICPAje3IduAC9v0hjZPW35uG78BuLGqflxVPwB2A2fOx05IkuZu1COA3wX+A/DTNv+zwPNV9VKb3wusatOrgD0AbfkLbfzf16dZR5I0ZrMGQJJ/BjxXVfcNl6cZWrMsO9w6w9vbnGQyyeTU1NRs7UmSXqdRjgDOAT6e5CngRganfn4XODbJ8jZmNbCvTe8FTgZoy98F7B+uT7PO36uqLVU1UVUTK1eunPMOSZJGM2sAVNXnq2p1Va1hcBH3zqr6DeA7wCfasI3ALW361jZPW35nVVWrX9zuEjoFWAvcO297Ikmak+WzD5nR54Abk/w28ABwfatfD/x+kt0M3vlfDFBVjya5CXgMeAm4vKpePoLtS5KOwJwCoKruAu5q008yzV08VfV3wEUzrH8NcM1cm5QkzT8/CSxJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjo1awAk+Zkk9yb5XpJHk/ynVj8lyT1JdiX5wyRHt/pb2/zutnzN0Gt9vtWfSHLeQu2UJGl2oxwB/Bj4aFWdBpwOrE9yNvAF4LqqWgscADa18ZuAA1X1XuC6No4kpwIXAx8E1gO/l2TZfO6MJGl0swZADfxNm31LexTwUeDmVt8GXNimN7R52vJzk6TVb6yqH1fVD4DdwJnzsheSpDkb6RpAkmVJHgSeA7YD3weer6qX2pC9wKo2vQrYA9CWvwD87HB9mnWGt7U5yWSSyampqbnvkSRpJCMFQFW9XFWnA6sZvGv/wHTD2nNmWDZT/dXb2lJVE1U1sXLlylHakyS9DnO6C6iqngfuAs4Gjk2yvC1aDexr03uBkwHa8ncB+4fr06wjSRqzUe4CWpnk2Db9NuBXgZ3Ad4BPtGEbgVva9K1tnrb8zqqqVr+43SV0CrAWuHe+dkSSNDfLZx/CScC2dsfOUcBNVfWnSR4Dbkzy28ADwPVt/PXA7yfZzeCd/8UAVfVokpuAx4CXgMur6uX53R1J0qhmDYCqegj40DT1J5nmLp6q+jvgohle6xrgmrm3KUmab34SWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdWrWAEhycpLvJNmZ5NEkn2n145JsT7KrPa9o9ST5UpLdSR5KcsbQa21s43cl2bhwuyVJms0oRwAvAf++qj4AnA1cnuRU4ArgjqpaC9zR5gHOB9a2x2bgyzAIDOBK4CzgTODKg6EhSRq/WQOgqp6pqvvb9F8DO4FVwAZgWxu2DbiwTW8AbqiBu4Fjk5wEnAdsr6r9VXUA2A6sn9e9kSSNbE7XAJKsAT4E3AOcWFXPwCAkgBPasFXAnqHV9rbaTPVXb2Nzkskkk1NTU3NpT5I0ByMHQJJ3AH8EfLaqfnS4odPU6jD1QwtVW6pqoqomVq5cOWp7kqQ5GikAkryFwR//r1XVH7fys+3UDu35uVbfC5w8tPpqYN9h6pKkRTDKXUABrgd2VtV/GVp0K3DwTp6NwC1D9Uvb3UBnAy+0U0S3A+uSrGgXf9e1miRpESwfYcw5wG8CDyd5sNV+C7gWuCnJJuBp4KK27DbgAmA38CJwGUBV7U9yNbCjjbuqqvbPy15IkuZs1gCoqu8y/fl7gHOnGV/A5TO81lZg61walCQtDD8JLEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSpWQMgydYkzyV5ZKh2XJLtSXa15xWtniRfSrI7yUNJzhhaZ2MbvyvJxoXZHUnSqEY5AvhvwPpX1a4A7qiqtcAdbR7gfGBte2wGvgyDwACuBM4CzgSuPBgakqTFMWsAVNX/BPa/qrwB2NamtwEXDtVvqIG7gWOTnAScB2yvqv1VdQDYzmtDRZI0Rq/3GsCJVfUMQHs+odVXAXuGxu1ttZnqkqRFMt8XgTNNrQ5Tf+0LJJuTTCaZnJqamtfmJEmveL0B8Gw7tUN7fq7V9wInD41bDew7TP01qmpLVU1U1cTKlStfZ3uSpNm83gC4FTh4J89G4Jah+qXtbqCzgRfaKaLbgXVJVrSLv+taTZK0SJbPNiDJ14GPAMcn2cvgbp5rgZuSbAKeBi5qw28DLgB2Ay8ClwFU1f4kVwM72rirqurVF5YlSWM0awBU1SUzLDp3mrEFXD7D62wFts6pO0nSgvGTwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVNjD4Ak65M8kWR3kivGvX1J0sBYAyDJMuC/AucDpwKXJDl1nD1IkgbGfQRwJrC7qp6sqp8ANwIbxtyDJAlIVY1vY8kngPVV9S/b/G8CZ1XVJ4fGbAY2t9n3AU8c4WaPB/7qCF9jPiyFPpZCD7A0+rCHVyyFPpZCD7A0+piPHt5TVStnG7T8CDcyV5mmdkgCVdUWYMu8bTCZrKqJ+Xq9N3IfS6GHpdKHPSytPpZCD0ulj3H2MO5TQHuBk4fmVwP7xtyDJInxB8AOYG2SU5IcDVwM3DrmHiRJjPkUUFW9lOSTwO3AMmBrVT26wJudt9NJR2gp9LEUeoCl0Yc9vGIp9LEUeoCl0cfYehjrRWBJ0tLhJ4ElqVMGgCR1ygCQpE6N+3MAGqMkZwJVVTvaV26sBx6vqtsWubUuJXk/g0++r2Lw+Zd9wK1VtXNRGxuzoTsA91XV/0jy68AvAzuBLVX1/xaprxuq6tLF2PZi8SLwPEvyaeCbVbVnkfu4ksF3Li0HtgNnAXcBvwrcXlXXjKmP9zP4g3dPVf3NUH19VX1rHD207f1D4J8z+BzKS8Au4OtV9cKYtv854BIGX3+yt5VXM/hDeGNVXTumPs4CdlbVj5K8DbgCOAN4DPidcfz3SPI1Bj+XxwDPA+8A/hg4l8HfpI1j6OHVt58H+BXgToCq+vhC9zCdJP+YwVfmPFJV317w7fUSAEkuq6qvjmE7LwB/C3wf+DrwjaqaWujtTtPHw8DpwFuBHwKrh37p76mqXxxDD58GLmfwzu504DNVdUtbdn9VnbHQPQz18WvAnwEXAA8CBxgEwr+pqrvG0MOfAx989bvb9m740apau9A9tO09CpzWbsneArwI3Mzgj+9pVfUvxtDDQ1X1i0mWA38JvLuqXk4S4Htj+tm8n0HofYXB0VgY/L5eDFBVf7bQPbQ+7q2qM9v0v2Lw+/JNYB3wJwv+xqCqungAT49pOw8wuLayDrgemAK+BWwE3jnG/X1guuk2/+CYengYeEebXgNMMgiB1/Q0hj6WteljgLva9M+Nqw/gcQbfz/Lq+nuAJ8b432Ln0PT9i/Rz8QhwNLAC+GvguFb/meH+FriHo4B/y+Do+PRWe3Jc/w5DfQz/nu4AVrbptwMPL/T231TXAJI8NNMi4MQxtVFV9VPg28C3k7yFwamYS4D/DMz6BU3z5CdJjqmqF4FfOlhM8i7gp2PqYVm10z5V9VSSjwA3J3kP038v1EJaDrzM4Ijona2np9u/zzh8FrgjyS7g4OnBnwPeC3xyxrXm3yNDR8PfSzJRVZNJfgEY17n36xkE4jLgPwLfSPIkcDaDU2QLrv2OXpfkG+35WRbnmuhRSVYwCKRUO1tQVX+b5KWF3vib6hRQ+0c8j8Hh/SGLgP9dVe8eQw8PVNWHZlj2tqr6vwvdQ9vWW6vqx9PUjwdOqqqHx9DDncC/q6oHh2rLga3Ab1TVsoXuoW3zM8Am4G7gw8AXquqrSVYCf1RVHx5TH0cxOL+7isHP5F5gR1W9PI7ttx7eBXwR+CcMvnHyDAaBtAf4dFV9b0x9vBugqvYlOZbBtamnq+recWx/mn4+BpxTVb815u0+xeANWRicivrlqvphkncA362q0xd0+2+yALge+GpVfXeaZX9QVb8+hh5+oar+fKG380aQZDXwUlX9cJpl51TV/xpjLx8EPsDg4trj49ruUpXkncDPM3jXu7eqnl3kljQkyTHAiVX1gwXdzpspACRJo/ODYJLUKQNAkjplAEhSpwwASerU/wdhfQgDCpPuiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's quickly take a look at the digit distribution in the\n",
    "#training data set\n",
    "#We can see an uneven distribution of the training data set\n",
    "bar = train['label'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, we need to scale the training and test sets\n",
    "#This will help with the accuracy of the model \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train);\n",
    "X_test_scaled = scaler.fit_transform(X_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Key Takeaways \n",
    "* In this section, we started by simply loaded our training and test data sets from CSV files \n",
    "* Next, we split the labels from each data set \n",
    "* We plotted a distribition of the digits in the training data set and noticed that not all the digits appear in the same amount\n",
    "* The final step was then to utilize StandardScaler to scale both the training and test data sets, which will help with the accuracy of our neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - Build Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To build out the neural networks, we will be utilized Tensorflow which is arguably the most popular library used for these kinds of exercises. Tensorflow has a clean interface, is scalable and flexible. As discussed, each neural network will have different hyperparameters which will produce different outcomes. This is a part of the benchmark experiment. \n",
    "\n",
    "#### We will be using Tensorflow's high-level API TF.learn to complete this task. Also, we will be recording the time it takes to train each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Classifier 1 Specs\n",
    "* Two hidden layers\n",
    "* 10 nodes per layer \n",
    "* ReLU activation function\n",
    "* 1000 training iterations using 20 batches of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code uses the DNNClassifier method to create the model object \n",
    "#with certain hyperparameters\n",
    "#Then the scaled training data and training labels are used to train it\n",
    "#We are also timing how long this block of code took to execute\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train_scaled)\n",
    "\n",
    "clf1_start_time =time.time()\n",
    "\n",
    "dnn_clf1 = tf.contrib.learn.DNNClassifier(hidden_units=[10,10], \n",
    "                                          n_classes=10,\n",
    "                                         feature_columns=feature_cols, \n",
    "                                         activation_fn = \"relu\")\n",
    "dnn_clf1 = tf.contrib.learn.SKCompat(dnn_clf1) \n",
    "dnn_clf1.fit(X_train_scaled, y_train, batch_size=20, steps=1000)\n",
    "\n",
    "clf1_elapsed_time = time.time() - clf1_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Classifier 2 Specs\n",
    "* Two hidden layers\n",
    "* 20 nodes per layer \n",
    "* Sigmoid activation function\n",
    "* 1000 training iterations using 20 batches of instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2_start_time =time.time()\n",
    "\n",
    "dnn_clf2 = tf.contrib.learn.DNNClassifier(hidden_units=[20,20], \n",
    "                                          n_classes=10,\n",
    "                                         feature_columns=feature_cols, \n",
    "                                         activation_fn = \"sigmoid\")\n",
    "dnn_clf2 = tf.contrib.learn.SKCompat(dnn_clf2)  \n",
    "dnn_clf2.fit(X_train_scaled, y_train, batch_size=20, steps=1000)\n",
    "\n",
    "clf2_elapsed_time = time.time() - clf2_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Classifier 3 Specs\n",
    "* Four hidden layers\n",
    "* 10 nodes per layer \n",
    "* ReLU activation function\n",
    "* 2000 training iterations using 40 batches of instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3_start_time =time.time()\n",
    "\n",
    "dnn_clf3 = tf.contrib.learn.DNNClassifier(hidden_units=[10,10,10,10],\n",
    "                                          n_classes=10,\n",
    "                                         feature_columns=feature_cols, \n",
    "                                         activation_fn = \"relu\")\n",
    "dnn_clf3 = tf.contrib.learn.SKCompat(dnn_clf3)  \n",
    "dnn_clf3.fit(X_train_scaled, y_train, batch_size=40, steps=2000)\n",
    "\n",
    "clf3_elapsed_time = time.time() - clf3_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Classifier 4 Specs\n",
    "* Four hidden layers\n",
    "* 20 nodes per layer \n",
    "* Sigmoid activation function\n",
    "* 2000 training iterations using 40 batches of instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf4_start_time =time.time()\n",
    "\n",
    "dnn_clf4 = tf.contrib.learn.DNNClassifier(hidden_units=[20, 20, 20, 20],\n",
    "                                          n_classes=10,\n",
    "                                         feature_columns=feature_cols, \n",
    "                                         activation_fn = \"sigmoid\")\n",
    "dnn_clf4 = tf.contrib.learn.SKCompat(dnn_clf4)  \n",
    "dnn_clf4.fit(X_train_scaled, y_train, batch_size=40, steps=2000)\n",
    "\n",
    "clf4_elapsed_time = time.time() - clf4_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways\n",
    "* This section was where we trained each neural network using the training data set \n",
    "* As discussed, we used a 2x2 design for the layers and nodes per layers \n",
    "* The first two models had 2 hidden layers and either 10 nodes or 20 nodes, respectively \n",
    "* The last two models had 4 hidden layers and either 10 nodes or 20 nodes, respectively\n",
    "* We alternated between activation functions -- choosing either ReLU or Sigmoid\n",
    "* Lastly, we changed between training iterations and batch sizes which is noted in the description\n",
    "* Overall, as expected, the development time for the first two models was faster given that iterations and hidden layer hyperparameters were smaller  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 - Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section will  calculate the classification accuracy for the training and test sets for each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpj4o1ycab\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90575"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier 1\n",
    "#This code uses the classifer that was built earlier.  \n",
    "#Scikit-Learn module is used to output Subset accuracy which is the\n",
    "#percentage of samples that have all their labels classified correctly\n",
    "#Train\n",
    "y_pred1_train = dnn_clf1.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred1_train['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpj4o1ycab\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "y_pred1_test = dnn_clf1.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred1_test['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpn17a472w\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8694666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier 2\n",
    "#Train\n",
    "y_pred2_train = dnn_clf2.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred2_train['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpn17a472w\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8698"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "y_pred2_test = dnn_clf2.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred2_test['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpcxoa73vl\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9243666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier 3\n",
    "#Train\n",
    "y_pred3_train = dnn_clf3.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred3_train['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpcxoa73vl\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "y_pred3_test = dnn_clf3.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred3_test['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpjp55gjz3\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37935"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier 4\n",
    "#Train\n",
    "y_pred4_train = dnn_clf4.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred4_train['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\HERNA_~1\\AppData\\Local\\Temp\\tmpjp55gjz3\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "y_pred4_test = dnn_clf4.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred4_test['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "* We used a holdout data set to make predictions using each of our classifiers \n",
    "* The results were divergent across all four sets which was an interesting outcome \n",
    "* Within each classifier, the accuracy scores between the training and test data sets were similar which can be interpreted as lack of overfitting. In other words, if the scores on the test data were lower than the training data, then we could infer overfitting exists\n",
    "* Another interesting observation is that the classifiers with less hidden layers performed better on average than the ones with more hidden layers (the classifiers with less hidden layers also had less training iterations and batch sizes)\n",
    "* The worst model as measured by the accuracy scores was Classifier 4 which had a value approximately less than half of the best model (Classifier 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5 - Benchmark Experiment Results and Final Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion from the benchmark study is that we should use Classifier 1. This neural network had the shortest processing time (6.75 seconds) compared to the other three classifiers and it had a accuracy score slightly over 90%, which was the second highest. The classifier that had a higher score took more than twice as long to build. We believe this is a suitable tradeoff because for a larger data set (also, one that we assume will continue to grow in order to keep training our model in the future), processing time becomes more important. A neural network with a slower processing time could have a real negative impact on the business. Overall, we recommend using a neural network with 2 hidden layers, 10 nodes per layer, ReLU activation function, 1000 training iterations, batch size of 20 and the default Adagrad optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Table.jpg \"Table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
