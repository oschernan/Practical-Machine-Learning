{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note- This content is copyrighted material:  \n",
    "CC-BY Attribution 4.0 International  \n",
    "Lynd Bacon & Associates, Ltd. DBA Loma Buena Associates   www.LBA.com  \n",
    "For information on permissible use, see https://creativecommons.org/licenses/by-sa/4.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will create some data \"assets\" for use by the XYZ company in direct marketing campaigns.  You will download data from the postgreSQL server to your local computer, create relational database tables that you'll store locally, create a \"flat\" file with selected customers and variables, and report on purchasing by gender.  You'll document your work by providing your commented code.  You'll save the new assets you created for future use and for sharing with others.\n",
    "\n",
    "To do this assignment you'll work with a Python script to connect to a Postgres server, the pandas package, and the sqlite database. You'll use Python and pandas for data manipulation and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Your Data from the PostgreSQL server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XYZ's data are in a Postgres DB server on the DSCC. To get them, log in to the SPS elasticsearch server. You'll need to do this using a VPN client if you are off campus.  Then, connect to the Postgres database server.\n",
    "\n",
    "You'll find three (3) tables in the Postgres DB pilot schema that are named **item**, **mail**, and **customer**.  retrieve each table along with the header record and create DataFrames out of each of these tables for further analysis using pandas. **Don't forget to log off from the vpn when done.**\n",
    "\n",
    "You'll find documentation about XYZ's data on Canvas.  Note that like most real world documentation, it's not \"perfect.\" But it is the *real thing*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do These Things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the following five (5) things, most of which have \"subthings:\"\n",
    " \n",
    "\n",
    " 1) Create a pandas DataFrame using the data obtained from each of the 3 tables.  \n",
    "\n",
    "> (a) Provide the code you used to do this.  \n",
    "\n",
    "> (b) Print out the column names of your item DataFrame and the first four (4) records in it.  \n",
    "\n",
    "> (c) Decribe the data types of the columns in the DataFrame. \n",
    "\n",
    " Include your commented code for each of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Write each of you pandas DataFrames to a local SQLite DB named `xyz.db.` Include **only** data for _active buyers_ in these tables. Verify that you have written the tables to your SQLite DB correctly. (Commented code, of course.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Now, using the same data as you used for 1), above, create a new *DataFrame* called `custSum` that you also write as a table to xyz.db, and that has the following characteristics.  This table should have one row per customer record.\n",
    "\n",
    "> (a) Include on each customer's record a binary, Y or N, indicator of whether the customer is a 'heavy buyer,' where the definition of a 'heavy buyer' is a customer whose LTD (life to date) purchasing (**ltd_sales**) is greater than 90% of the 2009 LTD purchasing of all customers. (**https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.quantile.html**) Verify your coding of this new variable by crosstabulating it with an indicator of whether their LTD purchasing is at at least the `90th` percentile of *all* LTD purchasing.\n",
    "\n",
    "> (b) Add to each customer's record whether the customer has the following credit cards:  AMEX, Discover, VISA, and Mastercard, with each credit card variable codes as a Y or a N for yes or no, respectively.  Document your creation of these codes by showing how they are related to the code values in the data (See columns: **amex_reg**,**amex_prem**, **disc_reg**,**disc_prem**,**visa_reg**,**visa_prem**,**mc_reg**,**mc_prem**.)\n",
    "\n",
    "> (c) Add to each customer's record their estimated HH income (**med_inc**), and the genders of adults \"1\" and \"2.\" (**adult1_g, adult2_g**) \n",
    "\n",
    "> (d) Add to each customer's record their ZIP code (**zip**) and ZIP+4 code (**zip4**).  \n",
    "\n",
    "> (e) Be sure to include the account number (**acctno**) on each record in the SQL tables you create so that the tables can be related to each other, later.\n",
    "\n",
    "> (f) Provide a count of the number of records in each table.  \n",
    "\n",
    "> (g) Verify that you have written this table to your SQLite DB correctly.\n",
    "\n",
    "(Don't forget to comment your code so that a reader can understand what it is supposed to do.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Create a new pandas DataFrame of data that will be used for target maketing and write it out to a headered csv file.  \n",
    "\n",
    "> (a) This DataFrame should have one row per customer.  The customers included should be active buyers or lapsed buyers.  \n",
    "\n",
    "> (b) The row for each customer should include the customer's account identifier (**acctno**), and an indicator variable (Y/N, or 1/0) for each product category (**Mobile Electronic Accessories**, **Small Appliances**, **Mobile Electronics**, **Home Audio**, **Portable Electronics**, **Cameras & Camcorder Accessori**,**Appliances**) the customer has made at least one purchase in.  \n",
    "\n",
    "> (c) Include for each customer their buyer status (**buyer_status**), and the total dollar amount of the purchases they have made from XYZ using all data available for him or her.  \n",
    "\n",
    "> (d) Write your DataFrame to a csv file, and also store it in a `shelve` database.\n",
    "\n",
    "> (e) Verify that the files you wrote your customer DataFrame to were written correctly.\n",
    "\n",
    "(Commented code, of course.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** At this point, part 5, though of interest, is _optional_ and will be *ungraded* given the time constraints.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Report the six (6) most frequently purchased product categories by the gender of \"adult 1\" using the data for the active customers.  Include for these categories the total spend in dollars on each category, the total number of products purchased in these categories, and the number of adults in each gender category.\n",
    "\n",
    "(Be sure to comment your code.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the above in up to six (6) pages, but in *no more than seven pages*, in a pdf file.  Be sure that everything is readable.  Address each of the five (5) above parts in turn.  Do 1 by providing your commented code and results. Then do 2 providing code + results, and so on.  Do _not_ provide a list of code for all of the above items in a block, followed by the results of your code in a block.  An assignment organized in this way will be returned ungraded. Be sure all of your code is syntactically correct, and that it approximates good Python coding style."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
