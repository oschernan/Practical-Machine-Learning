{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Principal Component Analysis - Oscar Hernandez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise involves benchmark testing of alternative modeling approaches. In particular, we will be focusing on developing a multiclass classifier that can correctly label a number image (0-9). The MNIST data set will be used to train each model which consists of 70000 observations and 784 features. At the end, we will make a recommendation of whether using PCA is helpful as a preliminary step of building a multiclass classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This report will cover the following: \n",
    "* Build a random forest classifier using the MNIST train and test data provided \n",
    "* Build a random forest classifier after using PCA on the entire MNIST data set \n",
    "* Build a random forest classifier after PCA using a different train/test method\n",
    "* Calculate the time it took to execute certain parts of the model building process and evaluate using F1 scores \n",
    "* Provide management recommendation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1 will involve training a random forest classifier using the 60000 observations in the train data set. We wil also evaluate how long it took to train the model and validate it on the test data set using a couple different methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load all the necessary modules \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the MNIST train data set which is 60,000 instances\n",
    "#Display the shape of the newly created object\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the MNIST test data set which is 10,000 instances\n",
    "#Display the shape of the newly created object\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, split the labels from train and test data set\n",
    "X_train = train.drop(\"label\", axis =1)\n",
    "y_train = train[\"label\"].copy()\n",
    "X_test = test.drop(\"label\", axis =1)\n",
    "y_test = test[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilize RandomForestClassifier to fit model using train data set \n",
    "forest_clf = RandomForestClassifier(n_estimators= 100, bootstrap=True,\n",
    "                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.29916071891785\n"
     ]
    }
   ],
   "source": [
    "#Fit a RF model using train data \n",
    "#Also, calculate how long it took to train the model \n",
    "rf_start_time =time.time()\n",
    "forest_clf.fit(X_train, y_train)\n",
    "rf_elapsed_time = time.time() - rf_start_time\n",
    "print (rf_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since the model is created, now we can evalute it on the \n",
    "#test data set using a couple different ways \n",
    "#First, we will use the model to predict new instances \n",
    "y_pred_forest = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98132256,  0.99118166,  0.96621622,  0.96153846,  0.97305541,\n",
       "        0.9689441 ,  0.98123045,  0.96477495,  0.95777549,  0.95072175])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now using the f1_score function, we will compute the F1 score\n",
    "#for each class and output it as an array \n",
    "f1_score(y_test, y_pred_forest, average= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.96      0.97      0.97      1032\n",
      "          3       0.96      0.97      0.96      1010\n",
      "          4       0.97      0.97      0.97       982\n",
      "          5       0.98      0.96      0.97       892\n",
      "          6       0.98      0.98      0.98       958\n",
      "          7       0.97      0.96      0.96      1028\n",
      "          8       0.96      0.95      0.96       974\n",
      "          9       0.95      0.95      0.95      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Alternatively, we can output the F1 scores using another function\n",
    "#that also outputs the precision and recall for each class \n",
    "print (classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92361458,  0.92661008,  0.9475    ,  0.96596597,  0.96643287])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lastly, we will use the cross_val_score function as another way\n",
    "#to validate the model; this uses K-Fold cross-validation \n",
    "cross_val_score(forest_clf, X_test, y_test, cv =5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways\n",
    "* This was a straightforward process that involved using the train and test data that was already split for us\n",
    "* It took 60 seconds to train the random forest algorithm using the train data \n",
    "* The average F1 score for all the classes was 97% which is very high "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section will focus on how PCA is used to lower the dimensions of the entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine the train and test data set into one dataframe using concat\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.20349931716919\n"
     ]
    }
   ],
   "source": [
    "#Initialize the PCA object and ensure that the principal components\n",
    "#generated explain 95% of the variability \n",
    "#Also, we will time how long it took to execute the code \n",
    "pca_start_time = time.time()\n",
    "pca = PCA(n_components=0.95, random_state =7)\n",
    "df_reduced = pca.fit_transform(df)\n",
    "pca_elapsed_time = time.time() - pca_start_time\n",
    "print (pca_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 154)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out how the reduced dataframe to see if PCA code worked\n",
    "df_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways\n",
    "* We combined both the train and test data sets to create one data frame\n",
    "* It took 39 seconds to the complete the PCA process using the new data frame \n",
    "* 95% of the variation can be explained by 154 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 - Random Forest Classifier w/ PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section is identical to Section 1 except that PCA will be incorporated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the reduced data frame from Section 2 into a train and test set \n",
    "train_reduced, test_reduced = df[:60000], df[60000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, split the labels from reduced train and test data set\n",
    "X_train_reduced = train_reduced.drop(\"label\", axis =1)\n",
    "y_train_reduced = train_reduced[\"label\"].copy()\n",
    "X_test_reduced = test_reduced.drop(\"label\", axis =1)\n",
    "y_test_reduced = test_reduced[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilize RandomForestClassifier to fit model using reduced train data set \n",
    "pca_forest_clf = RandomForestClassifier(n_estimators= 100, bootstrap=True, \n",
    "                                        random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.023298025131226\n"
     ]
    }
   ],
   "source": [
    "#Fit a RF model using reduced training data \n",
    "#Also, calculate how long it took to train the model \n",
    "pca_rf_start_time =time.time()\n",
    "pca_forest_clf.fit(X_train_reduced, y_train_reduced)\n",
    "pca_rf_elapsed_time = time.time() - pca_rf_start_time\n",
    "print (pca_rf_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since the model is created, now we can evalute it on the \n",
    "#reduced test data set  \n",
    "#First, we will use the model to predict new instances \n",
    "y_pred_pca_forest = pca_forest_clf.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.96      0.97      0.96      1032\n",
      "          3       0.96      0.97      0.96      1010\n",
      "          4       0.97      0.97      0.97       982\n",
      "          5       0.97      0.96      0.97       892\n",
      "          6       0.98      0.98      0.98       958\n",
      "          7       0.97      0.96      0.97      1028\n",
      "          8       0.96      0.96      0.96       974\n",
      "          9       0.96      0.95      0.95      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We will now output the F1 scores using classification_report function\n",
    "#that also outputs the precision and recall for each class \n",
    "print (classification_report(y_test_reduced, y_pred_pca_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 - Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly enough, the test performance (as measured by F1 scores) was identical for the original 784-variable model versus the 95-percent-PCA model. There were small differences between classes but the average at the end was the same. The original 784-variable model took 60 seconds to make while the 95-percent-PCA model took 95 seconds to make, which included the PCA process. The actual training of the PCA model was 55 seconds which was less than the original model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5 - Fix the Issue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We believe that data leakage is the flaw in this experiment. First, we are provided with the train and test data separately. However, during the process there wasn't any instructions on shuffling the train or test set which may negatively affect any cross-validation done on folds (some folds may be missing some digits). Another issue contributing to data leakage is that for Step 2, PCA was completed on the entire set which should only have been done on the train set excluding the labels. As such, the labels were used when completing PCA which shouldn't have been done. The test set excluding the labels should have been transformed separately.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are going to take the combined data set and reshuffle it \n",
    "df2 = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This will split into train and test sets \n",
    "train_2, test_2 = df2[:60000], df2[60000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, split the labels from new train and test data set\n",
    "X_train_2 = train_2.drop(\"label\", axis =1)\n",
    "y_train_2 = train_2[\"label\"].copy()\n",
    "X_test_2 = test_2.drop(\"label\", axis =1)\n",
    "y_test_2 = test_2[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.312687158584595\n"
     ]
    }
   ],
   "source": [
    "#Initialize the PCA object and ensure that the principal components\n",
    "#generated explain 95% of the variability \n",
    "#Also, we will time how long it took to execute the code \n",
    "new_start_time = time.time()\n",
    "pca_2 = PCA(n_components=0.95, random_state = 10).fit(X_train_2)\n",
    "X_train_reduced2 = pca_2.transform(X_train_2)\n",
    "new_elapsed_time = time.time() - new_start_time\n",
    "print (new_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14291596412658691\n"
     ]
    }
   ],
   "source": [
    "#Also, need to apply PCA to test set for validation later  \n",
    "#We will time this as well \n",
    "new2_start_time = time.time()\n",
    "X_test_reduced2 = pca_2.transform(X_test_2)\n",
    "new2_elapsed_time = time.time() - new2_start_time\n",
    "print(new2_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 154)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out how the new reduced train set to see if PCA code worked\n",
    "X_train_reduced2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilize RandomForestClassifier to fit model using new reduced train data set \n",
    "pca2_forest_clf = RandomForestClassifier(n_estimators= 100, bootstrap=True, \n",
    "                                         random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.92287611961365\n"
     ]
    }
   ],
   "source": [
    "#Fit a RF model using new reduced train data \n",
    "#Also, calculate how long it took to train the model \n",
    "pca2_rf_start_time =time.time()\n",
    "pca2_forest_clf.fit(X_train_reduced2, y_train_2)\n",
    "pca2_rf_elapsed_time = time.time() - pca2_rf_start_time\n",
    "print (pca2_rf_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since the model is created, now we can evalute it on the \n",
    "#new reduced test data set  \n",
    "#First, we will use the model to predict new instances \n",
    "y_pred_pca2_forest = pca2_forest_clf.predict(X_test_reduced2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97       948\n",
      "          1       0.97      0.98      0.98      1087\n",
      "          2       0.94      0.94      0.94      1012\n",
      "          3       0.92      0.92      0.92      1033\n",
      "          4       0.95      0.95      0.95       975\n",
      "          5       0.94      0.93      0.94       906\n",
      "          6       0.96      0.98      0.97       984\n",
      "          7       0.95      0.95      0.95      1064\n",
      "          8       0.91      0.92      0.92       982\n",
      "          9       0.94      0.91      0.93      1009\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We will now output the F1 scores using classification_report function\n",
    "#that also outputs the precision and recall for each class \n",
    "print (classification_report(y_test_2, y_pred_pca2_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways\n",
    "* The average F1 score for all the classes in this model was 95%, which is less than the model developed without PCA (97%)\n",
    "* The total development time for this section was 163 seconds \n",
    "* The time to train this RF model was 115 seconds which was almost 2X the time it took to train the model without PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Management Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When buildling ML models, predictive accuracy may come at the cost of development time. During this exercise, we timed various parts of the development process. Therefore, when considering implementing models for computer vision, I would recommend using PCA as a preliminary to machine learning classification. Although the development time was longer when utilizing PCA during this exercise, the accuracy (as measured by the F1 score) was very close (95% to 97%) to the non-PCA model. In particular when it comes to random forest algorithms, they don't tend to perform well on very high dimensional data therefore using PCA would be helpful. I would imagine that for larger data sets than the MNIST data set, using PCA would lead to better results versus not using it.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
